# recommender.py - VERSION AVEC HISTORIQUE CONVERSATIONNEL
"""
Moteur principal de recommandation de sujets
Combine embeddings s√©mantiques avec analyse LLM pour g√©n√©rer de NOUVEAUX sujets
inspir√©s par la base existante mais non pr√©sents dans les donn√©es
"""

import logging
import re
from typing import Dict, List, Optional
from datetime import datetime

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough

from embeddings import VectorStoreManager

logger = logging.getLogger(__name__)

class ThesisRecommender:
    """
    Syst√®me intelligent de recommandation de NOUVEAUX sujets de m√©moire
    inspir√©s par une base existante de sujets
    """
    
    def __init__(self, vectorstore_manager: VectorStoreManager):
        self.vectorstore = vectorstore_manager
        self.llm = self._initialize_llm()
        self.conversation_history = []  # Historique de conversation
        self.last_recommendations = []  # Derni√®res recommandations g√©n√©r√©es
        self.conversation_topic = None  # Th√®me en cours de conversation
        self.original_prompt = self._create_original_recommendation_prompt()
        self.new_topic_prompt = self._create_new_topic_prompt()
        self.elaboration_prompt = self._create_elaboration_prompt()
        
        logger.info("üéì Initialisation du ThesisRecommender (version conversationnelle)")
    
    def _initialize_llm(self):
        """Initialise le mod√®le de langage Gemini"""
        try:
            logger.info("ü§ñ Initialisation du LLM Gemini...")
            # Essaie gemma-3-1b-it d'abord, sinon gemini-pro
            try:
                return ChatGoogleGenerativeAI(
                    model="gemma-3-1b-it",
                    temperature=0.4,
                    max_tokens=1500
                )
            except:
                return ChatGoogleGenerativeAI(
                    model="gemini-pro",
                    temperature=0.4,
                    max_tokens=1500
                )
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation du LLM: {str(e)}")
            raise
    
    def _prepare_conversation_context(self) -> str:
        """
        Pr√©pare le contexte de conversation pour les prompts
        VERSION AM√âLIOR√âE
        """
        if not self.conversation_history:
            return "Premi√®re interaction. L'√©tudiant commence une nouvelle recherche."
        
        context_lines = []
        
        # Ajouter le th√®me en cours
        if self.conversation_topic:
            context_lines.append(f"TH√àME EN COURS : {self.conversation_topic}")
        
        # Ajouter les derniers √©changes (max 3 tours)
        recent_exchanges = []
        for i in range(min(6, len(self.conversation_history))):  # 3 tours complets
            msg = self.conversation_history[-(i+1)]
            role = "√âTUDIANT" if msg["role"] == "user" else "ASSISTANT"
            recent_exchanges.insert(0, f"{role}: {msg['content'][:80]}...")
        
        if recent_exchanges:
            context_lines.append("DERNIERS √âCHANGES :")
            context_lines.extend(recent_exchanges)
        
        # Ajouter les sujets pr√©c√©demment recommand√©s
        if self.last_recommendations:
            context_lines.append("\nSUJETS PR√âC√âDEMMENT RECOMMAND√âS :")
            for i, rec in enumerate(self.last_recommendations[:3], 1):
                title = rec.get('title', 'Sans titre')
                if len(title) > 50:
                    title = title[:47] + "..."
                context_lines.append(f"{i}. {title}")
        
        return "\n".join(context_lines)
        
    def _analyze_user_intent(self, user_input: str) -> Dict:
        """
        Analyse l'intention de l'utilisateur en fonction de l'input
        VERSION COMPL√àTE
        """
        intent = {
            "type": "new_query",
            "referenced_topic": None,
            "action": "generate",
            "topic_number": None,
            "raw_intent": user_input
        }
        
        input_lower = user_input.lower().strip()
        
        # 1. D√âTECTION DE R√âF√âRENCE √Ä UN SUJET PR√âC√âDENT (prioritaire)
        # Patterns pour "sujet 1", "le 1", "d√©veloppe le 1", etc.
        patterns = [
            # Patterns explicites avec num√©ro
            (r"(?:d√©veloppe|√©labore|explique|d√©cris|fais|propose|parle).*?(?:sujet|le|num√©ro|n¬∞)?\s*(\d+)", 1),
            (r"(?:sujet|le|num√©ro|n¬∞)\s*(\d+)", 1),
            (r"^(\d+)$", 1),  # Juste un chiffre
            (r"(\d+)(?:√®me|eme|er|√®re|ere)\s*(?:sujet|proposition|id√©e)", 1),
            
            # Patterns textuels pour les premiers sujets
            (r"premier\s*sujet", 1),
            (r"deuxi[√®e]me\s*sujet", 2),
            (r"troisi[√®e]me\s*sujet", 3),
            
            # Patterns de confirmation
            (r"celui\s*(?:la|l√†|ci)?\s*(\d+)", 1),
            (r"le\s*(\d+)(?:er|√®me|eme)?\s*(?:svp|stp|please|s'il te plait|s'il vous plait)", 1),
        ]
        
        for pattern, group_num in patterns:
            match = re.search(pattern, input_lower)
            if match:
                intent["type"] = "reference"
                intent["action"] = "elaborate"
                try:
                    # G√©rer les cas sp√©ciaux (premier, deuxi√®me, troisi√®me)
                    if "premier" in pattern:
                        intent["topic_number"] = 1
                    elif "deuxi√®me" in pattern or "deuxieme" in pattern:
                        intent["topic_number"] = 2
                    elif "troisi√®me" in pattern or "troisieme" in pattern:
                        intent["topic_number"] = 3
                    else:
                        intent["topic_number"] = int(match.group(group_num))
                    logger.info(f"üéØ R√©f√©rence d√©tect√©e: sujet {intent['topic_number']}")
                    return intent
                except (ValueError, IndexError) as e:
                    logger.warning(f"Erreur d'extraction du num√©ro: {e}")
                    continue
        
        # 2. D√âTECTION D'AUTRES INTENTIONS
        # Demande de conseil
        if any(word in input_lower for word in ["conseille", "recommandes", "sugg√®res", "proposes", "choisis", "lequel", "le mieux"]):
            intent["type"] = "advice"
            intent["action"] = "give_advice"
            logger.info("üéØ Intention: demande de conseil")
            return intent
        
        # Demande de d√©veloppement (sans num√©ro)
        if any(word in input_lower for word in ["d√©veloppe", "√©labore", "explique", "d√©taille", "approfondis"]):
            intent["type"] = "elaboration"
            intent["action"] = "elaborate"
            logger.info("üéØ Intention: demande de d√©veloppement g√©n√©ral")
            return intent
        
        # Demande de variation
        if any(word in input_lower for word in ["autre", "diff√©rent", "nouveau", "encore", "suivant", "variation"]):
            intent["type"] = "variation"
            intent["action"] = "generate_variation"
            logger.info("üéØ Intention: demande de variation")
            return intent
        
        # Changement de th√®me
        if any(word in input_lower for word in ["change", "autre th√®me", "diff√©rent sujet", "pas √ßa", "autre chose"]):
            intent["type"] = "change_topic"
            intent["action"] = "generate_new"
            logger.info("üéØ Intention: changement de th√®me")
            return intent
        
        # Demande de clarification
        if any(word in input_lower for word in ["quoi", "comment", "qu'est", "que veux", "explique"]):
            intent["type"] = "clarification"
            intent["action"] = "clarify"
            logger.info("üéØ Intention: demande de clarification")
            return intent
        
        logger.info(f"üìä Intention par d√©faut: nouvelle requ√™te")
        return intent
    
    def _create_original_recommendation_prompt(self):
        """Cr√©e le template de prompt pour analyser les sujets existants"""
        
        prompt_template = """Tu es un expert acad√©mique qui analyse des sujets de m√©moire existants pour inspirer de nouvelles id√©es.

    CONTEXTE DE LA CONVERSATION :
    {conversation_context}

    PROFIL DE L'√âTUDIANT :
    {student_profile}

    REQU√äTE ACTUELLE :
    {student_query}

    SUJETS EXISTANTS TROUV√âS (par similarit√©) :
    {similar_subjects}

    SCORES DE SIMILARIT√â (0-1) :
    {similarity_scores}

    INSTRUCTIONS STRICTES :
    1. Analyse uniquement les sujets fournis ci-dessus
    2. Pr√©sente 3 sujets maximum dans un format STRUCTUR√â
    3. Pour chaque sujet : Titre, Score, Pertinence, Th√®mes
    4. Ne sors pas du format ci-dessous
    5. Sois concis et pr√©cis

    FORMAT DE R√âPONSE OBLIGATOIRE (ne rien ajouter avant ou apr√®s) :

    ### üéØ ANALYSE DES SUJETS EXISTANTS

    **Sujet 1 :** [Titre exact du premier sujet]
    - **Score de similarit√© :** [score]
    - **Pertinence pour la requ√™te :** [1-2 phrases expliquant pourquoi ce sujet est pertinent]
    - **Th√®mes principaux :** [liste de 3-5 mots-cl√©s]

    **Sujet 2 :** [Titre exact du deuxi√®me sujet]
    - **Score de similarit√© :** [score]
    - **Pertinence pour la requ√™te :** [1-2 phrases]
    - **Th√®mes principaux :** [liste]

    **Sujet 3 :** [Titre exact du troisi√®me sujet]
    - **Score de similarit√© :** [score]
    - **Pertinence pour la requ√™te :** [1-2 phrases]
    - **Th√®mes principaux :** [liste]

    ### üîç TH√àMES R√âCURRENTS IDENTIFI√âS
    - [Th√®me 1]
    - [Th√®me 2]
    - [Th√®me 3]

    ### üí° PISTES D'INSPIRATION POUR UN SUJET ORIGINAL
    - [Piste 1 : suggestion concr√®te]
    - [Piste 2 : suggestion concr√®te]"""
        
        return ChatPromptTemplate.from_template(prompt_template)

    def _create_new_topic_prompt(self):
        """Cr√©e le template pour g√©n√©rer de NOUVEAUX sujets originaux"""
        
        prompt_template = """Tu es un directeur de recherche exp√©riment√© qui formule des sujets de m√©moire originaux et acad√©miquement valides.

    CONTEXTE DE LA CONVERSATION :
    {conversation_context}

    PROFIL DE L'√âTUDIANT :
    {student_profile}

    REQU√äTE ORIGINALE :
    {student_query}

    SUJETS EXISTANTS POUR INSPIRATION (NE PAS COPIER) :
    {existing_subjects}

    INSTRUCTIONS ABSOLUMENT CRITIQUES :
    1. Cr√©e 2-3 sujets COMPL√àTEMENT NOUVEAUX et ORIGINAUX
    2. Les sujets NE DOIVENT PAS EXISTER dans la liste ci-dessus
    3. Chaque sujet doit √™tre FAISABLE pour le niveau de l'√©tudiant
    4. Chaque sujet doit avoir un titre pr√©cis et une probl√©matique claire
    5. Suis strictement le format ci-dessous

    FORMAT DE R√âPONSE OBLIGATOIRE (ne rien ajouter avant ou apr√®s) :

    ### üöÄ NOUVEAUX SUJETS PROPOS√âS

    #### Sujet 1 : [TITRE PR√âCIS ET ACCROCHEUR]
    **üìå Probl√©matique :** [Question de recherche claire et sp√©cifique en 1 phrase]
    **üéØ Inspiration des sujets existants :** [Quel aspect t'a inspir√© ? Ex: "L'approche algorithmique du sujet X" mais PAS le m√™me titre]
    **üî¨ M√©thodologie sugg√©r√©e :** [Approche m√©thodologique concr√®te en 2-3 points]
    **üõ†Ô∏è Comp√©tences requises :** [Liste de comp√©tences techniques/th√©oriques]

    #### Sujet 2 : [TITRE PR√âCIS ET ACCROCHEUR]
    **üìå Probl√©matique :** [Question de recherche claire et sp√©cifique]
    **üéØ Inspiration des sujets existants :** [Quel aspect t'a inspir√© ?]
    **üî¨ M√©thodologie sugg√©r√©e :** [Approche m√©thodologique concr√®te]
    **üõ†Ô∏è Comp√©tences requises :** [Liste de comp√©tences]

    ### üìã RECOMMANDATIONS PRATIQUES
    - **Niveau de difficult√© :** [Facile/Interm√©diaire/Avanc√©]
    - **Dur√©e estim√©e :** [4-6 mois / 6-9 mois / 9-12 mois]
    - **Ressources cl√©s :** [2-3 r√©f√©rences ou outils principaux]
    - **Conseil :** [Conseil pratique pour d√©marrer]"""
        
        return ChatPromptTemplate.from_template(prompt_template)

    def _create_elaboration_prompt(self):
        """Cr√©e le template pour d√©velopper un sujet sp√©cifique"""
        
        prompt_template = """Tu es un directeur de m√©moire qui d√©veloppe un sujet sp√©cifique en profondeur.

    CONTEXTE DE LA CONVERSATION :
    {conversation_context}

    SUJET √Ä D√âVELOPPER (r√©f√©renc√© par l'√©tudiant) :
    {topic_to_elaborate}

    PROFIL DE L'√âTUDIANT :
    {student_profile}

    REQU√äTE DE D√âVELOPPEMENT :
    {student_query}

    INSTRUCTIONS :
    1. D√©veloppe CE sujet sp√©cifique, pas un autre
    2. Sois tr√®s concret et pratique
    3. Propose des √©tapes actionnables
    4. Inclus des d√©tails techniques pr√©cis

    FORMAT DE R√âPONSE OBLIGATOIRE :

    ### üéì D√âVELOPPEMENT DU SUJET : [TITRE DU SUJET]

    #### üìù PROBL√âMATIQUE APPROFONDIE
    **Question centrale :** [Formulation pr√©cise]
    **Contexte :** [Pourquoi cette question est importante]
    **Objectifs :** 
    - Objectif 1 : [Sp√©cifique et mesurable]
    - Objectif 2 : [Sp√©cifique et mesurable]
    - Objectif 3 : [Sp√©cifique et mesurable]

    #### üî¨ M√âTHODOLOGIE D√âTAILL√âE
    **√âtape 1 :** [Description d√©taill√©e avec outils concrets]
    **√âtape 2 :** [Description d√©taill√©e avec outils concrets]
    **√âtape 3 :** [Description d√©taill√©e avec outils concrets]
    **√âtape 4 :** [Description d√©taill√©e avec outils concrets]

    #### üõ†Ô∏è OUTILS ET TECHNOLOGIES
    - **Langages de programmation :** [Python, Java, etc.]
    - **Biblioth√®ques/Frameworks :** [TensorFlow, OpenCV, etc.]
    - **Outils d'analyse :** [Jupyter, Tableau, etc.]
    - **Donn√©es n√©cessaires :** [Sources et format]

    #### üìÖ PLAN DE TRAVAIL (6 MOIS)
    **Mois 1-2 :** [Revue litt√©rature + cadrage]
    **Mois 3-4 :** [Impl√©mentation + tests]
    **Mois 5 :** [Exp√©rimentations + analyse]
    **Mois 6 :** [R√©daction + validation]

    #### ‚ö†Ô∏è D√âFIS ANTICIP√âS ET SOLUTIONS
    1. **D√©fi :** [Description] ‚Üí **Solution :** [Proposition]
    2. **D√©fi :** [Description] ‚Üí **Solution :** [Proposition]

    #### üìö RESSOURCES RECOMMAND√âES
    - Article 1 : [R√©f√©rence pertinente]
    - Article 2 : [R√©f√©rence pertinente]
    - Tutoriel : [Lien utile]
    - Dataset : [Lien vers les donn√©es]"""
        
        return ChatPromptTemplate.from_template(prompt_template)
    
    def analyze_student_profile(self, input_text: str) -> Dict[str, str]:
        """
        Analyse le texte d'entr√©e de l'√©tudiant pour extraire le profil
        Version am√©lior√©e avec d√©tection de 'genie info'
        """
        try:
            # Normaliser le texte
            input_lower = input_text.lower()
            input_clean = re.sub(r'[^\w\s]', ' ', input_lower)
            
            profile = {
                "raw_input": input_text,
                "extracted_info": {},
                "timestamp": datetime.now().isoformat()
            }
            
            # D√©tection AVANC√âE de la facult√©
            faculty_patterns = {
                "G√©nie Civil": [
                    r"genie civil", r"g√©nie civil", r"civil", r"pont", r"b√©ton", 
                    r"structure", r"construction", r"b√¢timent"
                ],
                "G√©nie Informatique": [
                    r"genie info", r"g√©nie info", r"informatique", r"info", 
                    r"programmation", r"logiciel", r"donn√©e", r"base de donn√©e",
                    r"r√©seau", r"web", r"mobile", r"ia", r"intelligence artificielle",
                    r"machine learning", r"d√©veloppement"
                ],
                "G√©nie √âlectrique": [
                    r"genie electri", r"g√©nie electri", r"√©lectri", r"electri",
                    r"circuit", r"√©lectronique", r"automatique"
                ],
                "G√©nie M√©canique": [
                    r"genie mecan", r"g√©nie mecan", r"m√©canique", r"mecanique",
                    r"robot", r"automobile", r"thermique"
                ]
            }
            
            detected_faculty = None
            for faculty, patterns in faculty_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, input_clean):
                        detected_faculty = faculty
                        break
                if detected_faculty:
                    break
            
            if detected_faculty:
                profile["extracted_info"]["faculte"] = detected_faculty
            
            # D√©tection AVANC√âE du niveau
            level_patterns = {
                "L1": [r"\bl1\b", r"licence 1", r"premi√®re ann√©e", r"bac\+1"],
                "L2": [r"\bl2\b", r"licence 2", r"deuxi√®me ann√©e", r"bac\+2"],
                "L3": [r"\bl3\b", r"licence 3", r"licence", r"bac\+3", r"bac \+3"],
                "M1": [r"\bm1\b", r"master 1", r"bac\+4", r"master premi√®re ann√©e"],
                "M2": [r"\bm2\b", r"master 2", r"master", r"bac\+5", r"bac \+5"],
                "TECH2": [r"tech2", r"technicien 2", r"technicien", r"technique"]
            }
            
            detected_level = None
            for level, patterns in level_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, input_clean):
                        detected_level = level
                        break
                if detected_level:
                    break
            
            if detected_level:
                profile["extracted_info"]["niveau"] = detected_level
            
            # D√©tection des TH√âMATIQUES d'int√©r√™t (pour information uniquement, pas pour filtre)
            themes = []
            common_themes = {
                "compression": [r"compress", r"r√©duction", r"optimisation taille"],
                "image": [r"image", r"photo", r"visuel", r"multim√©dia"],
                "donn√©es": [r"donn√©e", r"data", r"base de donn√©e", r"bd"],
                "s√©curit√©": [r"s√©curit√©", r"securite", r"cyber", r"protection"],
                "r√©seau": [r"r√©seau", r"reseau", r"network", r"connexion"],
                "web": [r"web", r"internet", r"site", r"application web"],
                "mobile": [r"mobile", r"android", r"ios", r"application mobile"],
                "IA": [r"intelligence artificielle", r"ia", r"machine learning", r"ml", r"deep learning"],
                "cloud": [r"cloud", r"nuage", r"serveur distant", r"aws", r"azure"],
                "IoT": [r"iot", r"internet des objets", r"objet connect√©"]
            }
            
            for theme, patterns in common_themes.items():
                for pattern in patterns:
                    if re.search(pattern, input_clean):
                        if theme not in themes:
                            themes.append(theme)
                        break
            
            if themes:
                profile["extracted_info"]["thematiques"] = ", ".join(themes)
            
            # D√©tection des MOTS-CL√âS sp√©cifiques
            words = input_clean.split()
            keywords = [word for word in words if len(word) > 4 and word not in 
                       ['etude', 'etudes', 'travail', 'sujet', 'm√©moire', 'recherche']]
            
            if keywords:
                profile["extracted_info"]["mots_cles"] = ", ".join(keywords[:5])
            
            logger.info(f"üìã Profil analys√©: {profile['extracted_info']}")
            return profile
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'analyse du profil: {str(e)}")
            return {
                "raw_input": input_text,
                "extracted_info": {},
                "timestamp": datetime.now().isoformat()
            }
    
    def _prepare_filters(self, profile_info: dict) -> Optional[dict]:
        """
        Pr√©pare les filtres pour la recherche Chroma
        Chroma ne supporte qu'un seul champ de filtre √† la fois dans cette configuration
        """
        if not profile_info:
            return None
        
        # PRIORIT√â des filtres (utiliser un seul)
        if "faculte" in profile_info and profile_info["faculte"]:
            # Utiliser seulement la facult√© comme filtre
            logger.info(f"üîç Filtre appliqu√©: facult√© = {profile_info['faculte']}")
            return {"faculte": profile_info["faculte"]}
        elif "niveau" in profile_info and profile_info["niveau"]:
            # Sinon utiliser le niveau
            logger.info(f"üîç Filtre appliqu√©: niveau = {profile_info['niveau']}")
            return {"niveau": profile_info["niveau"]}
        else:
            # Si pas de facult√© ni niveau, ne pas filtrer
            logger.info("üîç Aucun filtre applicable (recherche sans filtre)")
            return None
    
    def find_similar_existing_topics(self, student_input: str, top_k: int = 8) -> Dict:
        """
        √âtape 1 : Trouver des sujets existants similaires pour inspiration
        Version corrig√©e avec filtres simplifi√©s
        """
        try:
            logger.info(f"üîç Recherche de sujets existants similaires...")
            
            # Analyser le profil
            profile = self.analyze_student_profile(student_input)
            
            # Pr√©parer les filtres (version simplifi√©e - un seul champ)
            filters = self._prepare_filters(profile["extracted_info"])
            
            # Rechercher les sujets similaires (avec ou sans filtre)
            similar_subjects = self.vectorstore.search_similar(
                query=student_input,
                k=top_k,
                filters=filters  # Peut √™tre None
            )
            
            if not similar_subjects:
                logger.warning("   Aucun sujet existant similaire trouv√©")
                return {
                    "success": False,
                    "message": "Aucun sujet similaire trouv√© dans la base",
                    "profile": profile
                }
            
            logger.info(f"   ‚úÖ {len(similar_subjects)} sujets existants trouv√©s")
            
            # Pr√©parer la pr√©sentation des sujets existants
            existing_subjects_text = "\n".join([
                f"{i+1}. {subject['metadata'].get('title', 'Sans titre')} "
                f"(Facult√©: {subject['metadata'].get('faculty', 'N/A')}, "
                f"Score: {subject['score']:.3f})"
                for i, subject in enumerate(similar_subjects)
            ])
            
            return {
                "success": True,
                "profile": profile,
                "existing_subjects": similar_subjects,
                "existing_subjects_text": existing_subjects_text,
                "count": len(similar_subjects)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la recherche des sujets existants: {str(e)}")
            # En cas d'erreur, essayer sans filtre
            try:
                logger.info("   Nouvelle tentative sans filtre...")
                similar_subjects = self.vectorstore.search_similar(
                    query=student_input,
                    k=top_k,
                    filters=None  # Sans filtre
                )
                
                if similar_subjects:
                    logger.info(f"   ‚úÖ {len(similar_subjects)} sujets trouv√©s (sans filtre)")
                    profile = self.analyze_student_profile(student_input)
                    
                    return {
                        "success": True,
                        "profile": profile,
                        "existing_subjects": similar_subjects,
                        "existing_subjects_text": "\n".join([
                            f"{i+1}. {s['metadata'].get('title', 'Sans titre')}"
                            for i, s in enumerate(similar_subjects)
                        ]),
                        "count": len(similar_subjects)
                    }
            except:
                pass
            
            return {
                "success": False,
                "error": str(e),
                "profile": {"raw_input": student_input}
            }
    
    def generate_new_topics(self, student_input: str, existing_topics_result: Dict) -> Dict:
        """
        √âtape 2 : G√©n√©rer de NOUVEAUX sujets inspir√©s par les sujets existants
        """
        try:
            if not existing_topics_result["success"]:
                return existing_topics_result
            
            logger.info("üß† G√©n√©ration de NOUVEAUX sujets inspir√©s...")
            
            profile = existing_topics_result["profile"]
            existing_subjects = existing_topics_result["existing_subjects"]
            
            # Pr√©parer le contexte de conversation
            conversation_context = self._prepare_conversation_context()
            
            # Pr√©parer le texte des sujets existants pour le prompt
            existing_details = "\n".join([
                f"{i+1}. [{subject['metadata'].get('faculty', 'N/A')} - "
                f"{subject['metadata'].get('level', 'N/A')}] "
                f"{subject['metadata'].get('title', 'Sans titre')[:80]}... | "
                f"Mots-cl√©s: {subject['metadata'].get('keywords', 'N/A')[:40]}..."
                for i, subject in enumerate(existing_subjects[:5])
            ])
            
            # Cha√Æne pour g√©n√©rer de NOUVEAUX sujets
            new_topic_chain = (
                {
                    "conversation_context": RunnablePassthrough(),
                    "student_profile": RunnablePassthrough(),
                    "student_query": RunnablePassthrough(),
                    "existing_subjects": RunnablePassthrough()
                }
                | self.new_topic_prompt
                | self.llm
            )
            
            new_topics = new_topic_chain.invoke({
                "conversation_context": conversation_context,
                "student_profile": str(profile["extracted_info"]),
                "student_query": student_input,
                "existing_subjects": existing_details
            })
            
            # Cha√Æne pour analyser les sujets existants (√©tape 1)
            analysis_chain = (
                {
                    "conversation_context": RunnablePassthrough(),
                    "student_profile": RunnablePassthrough(),
                    "student_query": RunnablePassthrough(),
                    "similar_subjects": RunnablePassthrough(),
                    "similarity_scores": RunnablePassthrough()
                }
                | self.original_prompt
                | self.llm
            )
            
            # Pr√©parer les scores pour l'analyse
            scores_text = "\n".join([
                f"{i+1}. {subject['score']:.3f}"
                for i, subject in enumerate(existing_subjects)
            ])
            
            subjects_text = "\n".join([
                f"{i+1}. {subject['content'][:150]}..."
                for i, subject in enumerate(existing_subjects)
            ])
            
            existing_analysis = analysis_chain.invoke({
                "conversation_context": conversation_context,
                "student_profile": str(profile["extracted_info"]),
                "student_query": student_input,
                "similar_subjects": subjects_text,
                "similarity_scores": scores_text
            })
            
            # Pr√©parer les sources d'inspiration pour le stockage
            inspiration_sources = [
                {
                    "title": subject["metadata"].get("title", "Sans titre"),
                    "score": subject["score"],
                    "faculty": subject["metadata"].get("faculty", "N/A"),
                    "level": subject["metadata"].get("level", "N/A"),
                    "keywords": subject["metadata"].get("keywords", "N/A")[:50],
                    "content_preview": subject["content"][:100] + "..."
                }
                for subject in existing_subjects[:3]
            ]
            
            # Mettre √† jour les derni√®res recommandations
            self.last_recommendations = inspiration_sources
            
            # Mettre √† jour le th√®me de conversation si disponible
            if "thematiques" in profile["extracted_info"]:
                self.conversation_topic = profile["extracted_info"]["thematiques"]
            elif "faculte" in profile["extracted_info"]:
                self.conversation_topic = profile["extracted_info"]["faculte"]
            
            # R√©sultat final combin√©
            result = {
                "success": True,
                "profile": profile,
                "existing_analysis": existing_analysis.content,
                "new_topics": new_topics.content,
                "inspiration_sources": inspiration_sources,
                "existing_count": len(existing_subjects),
                "conversation_topic": self.conversation_topic,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info("‚úÖ Nouveaux sujets g√©n√©r√©s avec succ√®s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration des nouveaux sujets: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "profile": existing_topics_result.get("profile", {})
            }
    
    
    def elaborate_topic(self, topic_number: int, student_input: str) -> Dict:
        """
        D√©veloppe un sujet sp√©cifique r√©f√©renc√© par l'utilisateur
        VERSION CORRIG√âE
        """
        try:
            logger.info(f"üîç D√©veloppement du sujet {topic_number}...")
            
            # V√©rifier si nous avons des recommandations pr√©c√©dentes
            if not self.last_recommendations:
                logger.warning("Aucune recommandation pr√©c√©dente trouv√©e")
                return {
                    "success": False,
                    "message": "‚ùå Aucun sujet pr√©c√©dent √† d√©velopper. Veuillez d'abord demander des recommandations avec 'help' pour voir les commandes disponibles.",
                    "suggestion": "D'abord, demandez des recommandations sur un th√®me. Exemple: 'Je cherche un sujet en g√©nie info sur la compression d'images'"
                }
            
            # V√©rifier si le num√©ro de sujet est valide
            if topic_number < 1 or topic_number > len(self.last_recommendations):
                available_topics = ", ".join([f"{i+1}" for i in range(len(self.last_recommendations))])
                logger.warning(f"Num√©ro de sujet invalide: {topic_number}. Disponibles: {available_topics}")
                return {
                    "success": False,
                    "message": f"‚ùå Sujet {topic_number} non disponible.",
                    "available_topics": f"Sujets disponibles: {available_topics}",
                    "suggestion": f"Veuillez choisir un num√©ro entre 1 et {len(self.last_recommendations)}"
                }
            
            # R√©cup√©rer le sujet √† d√©velopper
            topic_to_elaborate = self.last_recommendations[topic_number - 1]
            logger.info(f"üìå Sujet √† d√©velopper: {topic_to_elaborate.get('title', 'Sans titre')[:50]}...")
            
            # Analyser le profil actuel
            profile = self.analyze_student_profile(student_input)
            
            # Pr√©parer le contexte de conversation
            conversation_context = self._prepare_conversation_context()
            
            # Cha√Æne pour d√©velopper le sujet
            elaboration_chain = (
                {
                    "conversation_context": RunnablePassthrough(),
                    "topic_to_elaborate": RunnablePassthrough(),
                    "student_profile": RunnablePassthrough(),
                    "student_query": RunnablePassthrough()
                }
                | self.elaboration_prompt
                | self.llm
            )
            
            elaboration = elaboration_chain.invoke({
                "conversation_context": conversation_context,
                "topic_to_elaborate": f"Sujet {topic_number}: {topic_to_elaborate.get('title', 'Titre non disponible')}\n"
                                    f"Facult√©: {topic_to_elaborate.get('faculty', 'N/A')}\n"
                                    f"Niveau: {topic_to_elaborate.get('level', 'N/A')}\n"
                                    f"Mots-cl√©s: {topic_to_elaborate.get('keywords', 'N/A')}",
                "student_profile": str(profile["extracted_info"]),
                "student_query": student_input
            })
            
            # Ajouter √† l'historique de conversation
            self.conversation_history.append({
                "role": "assistant",
                "content": f"D√©veloppement du sujet {topic_number} termin√©",
                "timestamp": datetime.now().isoformat()
            })
            
            return {
                "success": True,
                "elaboration": elaboration.content,
                "topic_info": topic_to_elaborate,
                "topic_number": topic_number,
                "profile": profile,
                "conversation_topic": self.conversation_topic,
                "timestamp": datetime.now().isoformat(),
                "type": "elaboration"
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du d√©veloppement du sujet: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "topic_number": topic_number,
                "message": "Une erreur est survenue lors du d√©veloppement du sujet."
            }
    
    def recommend(self, student_input: str, top_k: int = 8, conversation_context: dict = None) -> Dict:
        """
        Processus complet de recommandation avec contexte conversationnel
        VERSION AM√âLIOR√âE AVEC GESTION D'INTENTIONS COMPL√àTE
        """
        # Ajouter √† l'historique de conversation
        self.conversation_history.append({
            "role": "user",
            "content": student_input,
            "timestamp": datetime.now().isoformat()
        })
        
        # Limiter la taille de l'historique
        if len(self.conversation_history) > 10:
            self.conversation_history = self.conversation_history[-10:]
        
        # Analyser l'intention de l'utilisateur
        intent = self._analyze_user_intent(student_input)
        
        try:
            logger.info(f"üéØ Traitement de la requ√™te: '{student_input[:80]}...'")
            logger.info(f"   Intention d√©tect√©e: {intent['type']} | Action: {intent['action']} | Topic: {intent['topic_number']}")
            
            # ================= TRAITEMENT SP√âCIFIQUE PAR TYPE D'INTENTION =================
            
            # 1. INTENTION: R√âF√âRENCE √Ä UN SUJET PR√âC√âDENT (ex: "sujet 1", "d√©veloppe le 2")
            if intent["type"] == "reference" and intent["topic_number"]:
                logger.info(f"   ‚û°Ô∏è D√©veloppement du sujet {intent['topic_number']} demand√©")
                result = self.elaborate_topic(intent["topic_number"], student_input)
                
                # Si succ√®s, ajouter √† l'historique
                if result.get("success"):
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": f"D√©veloppement du sujet {intent['topic_number']} termin√©",
                        "timestamp": datetime.now().isoformat()
                    })
                
                return result
            
            # 2. INTENTION: DEMANDE DE CONSEIL (ex: "conseille-moi", "lequel choisir")
            elif intent["type"] == "advice":
                logger.info("   ‚û°Ô∏è Demande de conseil d√©tect√©e")
                
                if not self.last_recommendations:
                    return {
                        "success": False,
                        "message": "‚ùå Aucun sujet pr√©c√©dent √† conseiller.",
                        "suggestion": "D'abord, demandez des recommandations sur un th√®me. Exemple: 'Je cherche un sujet en g√©nie info sur la compression d'images'",
                        "type": "advice_error"
                    }
                
                # G√©n√©rer des conseils bas√©s sur le profil et les sujets pr√©c√©dents
                advice_prompt = ChatPromptTemplate.from_template("""Tu es un conseiller acad√©mique exp√©riment√©.

    CONTEXTE DE CONVERSATION :
    {conversation_context}

    SUJETS PR√âC√âDEMENT RECOMMAND√âS :
    {previous_topics}

    PROFIL DE L'√âTUDIANT :
    {student_profile}

    DEMANDE DE CONSEIL :
    {student_query}

    INSTRUCTIONS :
    1. Analyse les sujets pr√©c√©dents et le profil de l'√©tudiant
    2. Recommande le sujet le plus adapt√© avec des arguments concrets
    3. Compare bri√®vement les options
    4. Donne des conseils pratiques pour le choix

    FORMAT DE R√âPONSE :

    ### ü§ù CONSEIL PERSONNALIS√â

    #### üèÜ SUJET RECOMMAND√â : [Num√©ro et titre]
    **Pourquoi ce sujet est id√©al pour vous :**
    - [Argument 1 bas√© sur votre profil]
    - [Argument 2 bas√© sur vos comp√©tences]
    - [Argument 3 bas√© sur vos int√©r√™ts]

    #### üìä COMPARATIF RAPIDE
    1. **Sujet 1 :** [Avantage principal] / [Inconv√©nient principal]
    2. **Sujet 2 :** [Avantage principal] / [Inconv√©nient principal]
    3. **Sujet 3 :** [Avantage principal] / [Inconv√©nient principal]

    #### üéØ CRIT√àRES DE CHOIX
    - Crit√®re 1 : [Explication]
    - Crit√®re 2 : [Explication]
    - Crit√®re 3 : [Explication]

    #### üí° PROCHAINES √âTAPES
    1. [Action concr√®te 1]
    2. [Action concr√®te 2]
    3. [Action concr√®te 3]""")
                
                chain = advice_prompt | self.llm
                conversation_context_text = self._prepare_conversation_context()
                
                # Pr√©parer la liste des sujets pr√©c√©dents
                previous_topics_text = "\n".join([
                    f"{i+1}. {rec.get('title', 'Sans titre')} "
                    f"({rec.get('faculty', 'N/A')}, {rec.get('level', 'N/A')}) - "
                    f"Mots-cl√©s: {rec.get('keywords', 'N/A')[:50]}"
                    for i, rec in enumerate(self.last_recommendations[:3])
                ])
                
                profile = self.analyze_student_profile(student_input)
                advice = chain.invoke({
                    "conversation_context": conversation_context_text,
                    "previous_topics": previous_topics_text,
                    "student_profile": str(profile["extracted_info"]),
                    "student_query": student_input
                })
                
                result = {
                    "success": True,
                    "advice": advice.content,
                    "available_topics": self.last_recommendations[:3],
                    "profile": profile,
                    "type": "advice",
                    "conversation_topic": self.conversation_topic,
                    "timestamp": datetime.now().isoformat()
                }
                
                self.conversation_history.append({
                    "role": "assistant",
                    "content": f"Conseil donn√© sur {len(self.last_recommendations[:3])} sujets",
                    "timestamp": datetime.now().isoformat()
                })
                
                return result
            
            # 3. INTENTION: CHANGEMENT DE TH√àME (ex: "changeons de sujet", "autre th√®me")
            elif intent["type"] == "change_topic":
                logger.info("üîÑ Changement de th√®me d√©tect√©")
                self.conversation_topic = None
                self.last_recommendations = []  # Effacer aussi les recommandations pr√©c√©dentes
                
                # R√©pondre avec confirmation
                return {
                    "success": True,
                    "message": "‚úÖ Th√®me de conversation r√©initialis√©.",
                    "suggestion": "Parlez-moi de votre nouveau centre d'int√©r√™t. Exemple: 'Je m'int√©resse maintenant √† la s√©curit√© r√©seau'",
                    "type": "topic_change",
                    "timestamp": datetime.now().isoformat()
                }
            
            # 4. INTENTION: D√âVELOPPEMENT G√âN√âRAL (sans num√©ro sp√©cifique)
            elif intent["type"] == "elaboration" and not intent["topic_number"]:
                logger.info("   ‚û°Ô∏è Demande de d√©veloppement g√©n√©ral")
                
                if not self.last_recommendations:
                    return {
                        "success": False,
                        "message": "‚ùå Aucun sujet pr√©c√©dent √† d√©velopper.",
                        "suggestion": "D'abord, demandez des recommandations sp√©cifiques. Essayez: 'Propose-moi des sujets sur [votre th√®me]'",
                        "type": "elaboration_error"
                    }
                
                # Demander √† l'utilisateur de pr√©ciser
                available_topics_info = "\n".join([
                    f"{i+1}. {rec.get('title', 'Sans titre')[:60]}..."
                    for i, rec in enumerate(self.last_recommendations[:3])
                ])
                
                return {
                    "success": True,
                    "message": "üìã Plusieurs sujets disponibles pour d√©veloppement.",
                    "available_topics": self.last_recommendations[:3],
                    "prompt": f"Pr√©cisez le num√©ro du sujet √† d√©velopper:\n{available_topics_info}",
                    "type": "clarification_needed",
                    "timestamp": datetime.now().isoformat()
                }
            
            # 5. INTENTION: VARIATION OU NOUVEAUX SUJETS (cas par d√©faut)
            else:
                logger.info("   ‚û°Ô∏è G√©n√©ration de nouveaux sujets demand√©e")
                
                # V√©rifier si c'est une demande de variation sur th√®me existant
                if intent["type"] == "variation" and self.conversation_topic:
                    logger.info(f"   Variation demand√©e sur le th√®me: {self.conversation_topic}")
                    # Ajouter une indication de variation dans la requ√™te
                    student_input = f"{student_input} (variation sur: {self.conversation_topic})"
                
                # √âtape 1 : Trouver des sujets existants pour inspiration
                existing_topics = self.find_similar_existing_topics(student_input, top_k)
                
                if not existing_topics["success"]:
                    # M√™me si aucun sujet similaire n'est trouv√©, on peut quand m√™me g√©n√©rer des sujets
                    logger.info("   Aucun sujet similaire trouv√©, g√©n√©ration bas√©e sur le profil uniquement")
                    profile = self.analyze_student_profile(student_input)
                    
                    # Utiliser un prompt sp√©cial pour g√©n√©rer sans inspiration
                    no_inspiration_prompt = ChatPromptTemplate.from_template("""Tu es un expert en cr√©ation de sujets de m√©moire.

    CONTEXTE DE CONVERSATION :
    {conversation_context}

    PROFIL DE L'√âTUDIANT :
    {student_profile}

    REQU√äTE SP√âCIFIQUE :
    {student_query}

    INSTRUCTIONS :
    1. Cr√©e 2-3 sujets ORIGINAUX et ACAD√âMIQUEMENT VALIDES
    2. Adapte les sujets au profil de l'√©tudiant
    3. Sois concret et pr√©cis

    FORMAT DE R√âPONSE :

    ### üöÄ NOUVEAUX SUJETS PROPOS√âS

    #### Sujet 1 : [TITRE PR√âCIS]
    **üìå Probl√©matique :** [Question de recherche en 1 phrase]
    **üéØ Pourquoi ce sujet vous convient :** [2-3 arguments bas√©s sur votre profil]
    **üî¨ Approche m√©thodologique :** [M√©thode principale]
    **üõ†Ô∏è Comp√©tences mobilis√©es :** [2-3 comp√©tences cl√©s]

    #### Sujet 2 : [TITRE PR√âCIS]
    **üìå Probl√©matique :** [Question de recherche]
    **üéØ Pourquoi ce sujet vous convient :** [Arguments]
    **üî¨ Approche m√©thodologique :** [M√©thode]
    **üõ†Ô∏è Comp√©tences mobilis√©es :** [Comp√©tences]

    ### üí° CONSEILS POUR COMMENCER
    - [Conseil pratique 1]
    - [Conseil pratique 2]""")
                    
                    chain = no_inspiration_prompt | self.llm
                    conversation_context_text = self._prepare_conversation_context()
                    
                    new_topics = chain.invoke({
                        "conversation_context": conversation_context_text,
                        "student_profile": str(profile["extracted_info"]),
                        "student_query": student_input
                    })
                    
                    # Mettre √† jour le th√®me de conversation
                    if "thematiques" in profile["extracted_info"]:
                        self.conversation_topic = profile["extracted_info"]["thematiques"]
                    elif "faculte" in profile["extracted_info"]:
                        self.conversation_topic = profile["extracted_info"]["faculte"]
                    
                    result = {
                        "success": True,
                        "profile": profile,
                        "existing_analysis": "‚ÑπÔ∏è Aucun sujet similaire trouv√© dans la base. Ces suggestions sont cr√©√©es sp√©cialement pour vous.",
                        "new_topics": new_topics.content,
                        "inspiration_sources": [],
                        "existing_count": 0,
                        "conversation_topic": self.conversation_topic,
                        "timestamp": datetime.now().isoformat(),
                        "type": "new_topics_no_inspiration"
                    }
                    
                else:
                    # √âtape 2 : G√©n√©rer de NOUVEAUX sujets inspir√©s
                    logger.info(f"   ‚úÖ {existing_topics['count']} sujets d'inspiration trouv√©s")
                    final_result = self.generate_new_topics(student_input, existing_topics)
                    result = final_result
                    result["type"] = "new_topics_with_inspiration"
                
                # Stocker les sources d'inspiration pour r√©f√©rence future
                if "inspiration_sources" in result and result["inspiration_sources"]:
                    self.last_recommendations = result["inspiration_sources"]
                    logger.info(f"   üíæ {len(result['inspiration_sources'])} recommandations stock√©es")
                
                # Ajouter √† l'historique de conversation
                self.conversation_history.append({
                    "role": "assistant",
                    "content": f"{len(result.get('inspiration_sources', []))} sujets d'inspiration trouv√©s, {result.get('existing_count', 0)} sujets analys√©s",
                    "timestamp": datetime.now().isoformat(),
                    "metadata": {
                        "topics_generated": True,
                        "inspiration_count": len(result.get('inspiration_sources', [])),
                        "topic": result.get('conversation_topic', 'g√©n√©ral')
                    }
                })
                
                return result
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du processus de recommandation: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # Ajouter l'erreur √† l'historique
            self.conversation_history.append({
                "role": "assistant",
                "content": f"Erreur lors du traitement: {str(e)[:80]}...",
                "timestamp": datetime.now().isoformat(),
                "metadata": {"error": True}
            })
            
            return {
                "success": False,
                "error": str(e),
                "message": "‚ùå Une erreur technique est survenue. Essayez de reformuler votre demande.",
                "suggestion": "Veuillez r√©essayer avec une formulation plus simple ou tapez 'clear' pour r√©initialiser.",
                "profile": {"raw_input": student_input},
                "conversation_topic": self.conversation_topic,
                "type": "error"
            }
    
    def get_system_status(self) -> Dict:
        """Retourne l'√©tat du syst√®me"""
        return {
            "llm_initialized": self.llm is not None,
            "vectorstore_info": self.vectorstore.get_vectorstore_info(),
            "conversation_history_count": len(self.conversation_history),
            "last_recommendations_count": len(self.last_recommendations),
            "current_topic": self.conversation_topic,
            "timestamp": datetime.now().isoformat(),
            "version": "3.0 - Conversationnel Intelligent"
        }
    
    def clear_conversation(self):
        """Efface l'historique de conversation"""
        self.conversation_history = []
        self.last_recommendations = []
        self.conversation_topic = None
        logger.info("üóëÔ∏è  Conversation effac√©e")

if __name__ == "__main__":
    # Test du module
    print("‚úÖ Module recommender.py (version conversationnelle) charg√© avec succ√®s")


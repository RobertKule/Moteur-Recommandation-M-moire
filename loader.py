# loader.py
"""
Chargement et pr√©paration du dataset de sujets de m√©moire
Gestion robuste des formats CSV acad√©miques
"""

import pandas as pd
import logging
from pathlib import Path

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_thesis_data(csv_path: str = "data/Sujet_EtudiantsB.csv") -> pd.DataFrame:
    """
    Charge le fichier CSV des sujets de m√©moire
    G√®re les cas particuliers (guillemets multilignes, retours √† la ligne, etc.)
    
    Args:
        csv_path: Chemin vers le fichier CSV
        
    Returns:
        DataFrame nettoy√© et pr√™t pour l'analyse
    """
    
    csv_path = Path(csv_path)
    
    if not csv_path.exists():
        logger.error(f"‚ùå Fichier non trouv√© : {csv_path}")
        raise FileNotFoundError(f"Fichier CSV introuvable : {csv_path}")
    
    logger.info(f"üìÇ Chargement du fichier : {csv_path}")
    
    try:
        # Lecture robuste du CSV (car contient des guillemets multilignes)
        df = pd.read_csv(
            csv_path,
            sep=";",
            encoding="utf-8",
            engine="python",
            on_bad_lines="skip",
            quotechar='"'
        )
        
        logger.info(f"‚úÖ CSV charg√© : {len(df)} lignes, {len(df.columns)} colonnes")
        logger.info(f"Colonnes d√©tect√©es : {list(df.columns)}")
        
        # V√©rification des colonnes essentielles
        essential_columns = ["thesis_title", "description_sujet"]
        missing = [col for col in essential_columns if col not in df.columns]
        
        if missing:
            logger.warning(f"‚ö†Ô∏è Colonnes manquantes : {missing}")
            logger.warning("Utilisation des premi√®res colonnes disponibles")
            # Utilise la premi√®re colonne comme titre si thesis_title manque
            if "thesis_title" not in df.columns and len(df.columns) > 0:
                df = df.rename(columns={df.columns[0]: "thesis_title"})
        
        # Nettoyage de base
        df = df.dropna(subset=["thesis_title"]).reset_index(drop=True)
        
        # Cr√©ation d'un texte complet pour l'embedding
        df["full_text"] = df.apply(_create_full_text, axis=1)
        
        logger.info(f"üéØ {len(df)} sujets pr√©par√©s pour l'analyse s√©mantique")
        return df
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du chargement du CSV : {str(e)}")
        raise

def _create_full_text(row) -> str:
    """
    Cr√©e un texte complet √† partir des informations d'un sujet
    """
    parts = []
    
    # Titre
    if "thesis_title" in row and pd.notna(row["thesis_title"]):
        parts.append(f"Titre: {row['thesis_title']}")
    
    # Mots-cl√©s
    if "thesis_keywords" in row and pd.notna(row["thesis_keywords"]):
        parts.append(f"Mots-cl√©s: {row['thesis_keywords']}")
    
    # Probl√©matique
    if "Probl√©matique" in row and pd.notna(row["Probl√©matique"]):
        parts.append(f"Probl√©matique: {row['Probl√©matique']}")
    
    # Description
    if "description_sujet" in row and pd.notna(row["description_sujet"]):
        parts.append(f"Description: {row['description_sujet']}")
    
    # M√©thode
    if "M√©thode" in row and pd.notna(row["M√©thode"]):
        parts.append(f"M√©thode: {row['M√©thode']}")
    
    # Technologies
    if "technologies" in row and pd.notna(row["technologies"]):
        parts.append(f"Technologies: {row['technologies']}")
    
    return " | ".join(parts)

if __name__ == "__main__":
    # Test du chargement
    df = load_thesis_data()
    print(f"\nüîç Aper√ßu des donn√©es :")
    print(df[["thesis_title", "student_faculty", "student_level"]].head())
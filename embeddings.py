# embeddings.py - VERSION CORRIG√âE
"""
Gestion des embeddings s√©mantiques et de la base vectorielle ChromaDB
"""

import logging
import chromadb
from pathlib import Path
from typing import List, Tuple
import os
import shutil

# ‚úÖ D√âFINIR LE LOGGER AU D√âBUT
logger = logging.getLogger(__name__)

# Import pour Chroma - utilise la nouvelle version
try:
    from langchain_chroma import Chroma
    chroma_source = "langchain_chroma"
except ImportError:
    try:
        from langchain_community.vectorstores import Chroma
        chroma_source = "langchain_community"
    except ImportError as e:
        logger.error(f"‚ùå Impossible d'importer Chroma: {e}")
        raise

# Import pour HuggingFace embeddings
try:
    from langchain_huggingface import HuggingFaceEmbeddings
    hf_source = "langchain_huggingface"
except ImportError:
    try:
        from langchain_community.embeddings import HuggingFaceEmbeddings
        hf_source = "langchain_community"
    except ImportError:
        raise ImportError("Installez langchain-huggingface ou langchain-community: pip install langchain-huggingface")

logger.info(f"‚úÖ Import Chroma depuis: {chroma_source}")
logger.info(f"‚úÖ Import HuggingFace depuis: {hf_source}")

class VectorStoreManager:
    """
    G√®re la cr√©ation et l'acc√®s √† la base vectorielle des sujets
    """
    
    def __init__(self, persist_directory: str = "chroma_db"):
        self.persist_directory = Path(persist_directory)
        self.embeddings = None
        self.vectorstore = None
        self._initialize_embeddings()
    
    def _initialize_embeddings(self):
        """Initialise le mod√®le d'embeddings local (Sentence Transformers)"""
        try:
            logger.info("ü§ñ Initialisation des embeddings locaux (Sentence Transformers)...")
            
            # Configuration du mod√®le HuggingFace
            self.embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2",
                model_kwargs={'device': 'cpu'},  # Change en 'cuda' si tu as un GPU
                encode_kwargs={
                    'normalize_embeddings': True,
                    'batch_size': 32
                }
            )
            
            logger.info("‚úÖ Embeddings locaux initialis√©s")
            logger.info(f"üìå Mod√®le: all-MiniLM-L6-v2")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'initialisation des embeddings: {str(e)}")
            raise
    
    def ensure_vectorstore(self, texts: List[str], metadatas: List[dict] = None) -> bool:
        """
        S'assure qu'une base vectorielle existe, la cr√©e si n√©cessaire
        """
        try:
            # V√©rifier si une base valide existe d√©j√†
            if self._has_valid_chroma_db():
                logger.info(f"üìÇ Chargement du vectorstore existant...")
                self.vectorstore = Chroma(
                    persist_directory=str(self.persist_directory),
                    embedding_function=self.embeddings,
                    collection_name="thesis_subjects"
                )
                
                # V√©rifier le contenu
                try:
                    count = self.vectorstore._collection.count()
                    logger.info(f"‚úÖ Vectorstore charg√©: {count} sujets index√©s")
                    
                    if count > 0:
                        return True
                    else:
                        logger.warning("‚ö†Ô∏è  Base vide d√©tect√©e, recr√©ation...")
                except:
                    logger.warning("‚ö†Ô∏è  Base corrompue, recr√©ation...")
            
            # Cr√©er une nouvelle base (soit pas de base, soit base vide/corrompue)
            logger.info(f"üß† Cr√©ation d'un nouveau vectorstore avec {len(texts)} sujets...")
            
            # S'assurer que le dossier existe
            self.persist_directory.mkdir(parents=True, exist_ok=True)
            
                        # Cr√©er la base vectorielle - la persistance est souvent automatique
            self.vectorstore = Chroma.from_texts(
                texts=texts,
                embedding=self.embeddings,
                metadatas=metadatas,
                persist_directory=str(self.persist_directory),
                collection_name="thesis_subjects"
            )
            
            # AVEC les nouvelles versions, NE PAS appeler .persist() explicitement
            # La base est automatiquement sauvegard√©e dans `persist_directory`
            
            # Donner un peu de temps pour l'√©criture sur disque (optionnel mais recommand√©)
            import time
            time.sleep(2)  # Augment√© √† 2 secondes pour √™tre s√ªr
            
            # V√©rifier que la cr√©ation a fonctionn√© en acc√©dant √† la collection
            # Cela force √©galement l'initialisation si n√©cessaire
            try:
                _ = self.vectorstore._collection
            except:
                pass  # Ignorer les erreurs d'acc√®s, l'important est que l'objet existe
            
            # V√©rifier la cr√©ation
            count = self.vectorstore._collection.count()
            logger.info(f"‚úÖ Nouveau vectorstore cr√©√©: {count} sujets index√©s")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur critique avec le vectorstore: {str(e)}")
            
            # Tentative de nettoyage et recr√©ation
            try:
                self._force_recreate(texts, metadatas)
                return True
            except:
                return False
    
    def _has_valid_chroma_db(self) -> bool:
        """V√©rifie si une base Chroma valide existe"""
        if not self.persist_directory.exists():
            return False
        
        # V√©rifier les fichiers Chroma essentiels
        required_files = ["chroma.sqlite3", "chroma.sqlite3-wal"]
        chroma_files_exist = False
        
        for file in required_files:
            if (self.persist_directory / file).exists():
                chroma_files_exist = True
                break
        
        if not chroma_files_exist:
            logger.debug(f"‚ÑπÔ∏è  Dossier {self.persist_directory} existe mais sans fichiers Chroma")
            return False
        
        return True
    
    def _force_recreate(self, texts: List[str], metadatas: List[dict]):
        """Force la recr√©ation compl√®te de la base"""
        logger.warning("üîÑ Forcer la recr√©ation de la base vectorielle...")
        
        # Supprimer le dossier existant
        if self.persist_directory.exists():
            shutil.rmtree(self.persist_directory)
        
        # Recr√©er le dossier
        self.persist_directory.mkdir(parents=True, exist_ok=True)
        
        # Cr√©er une nouvelle base
        self.vectorstore = Chroma.from_texts(
            texts=texts,
            embedding=self.embeddings,
            metadatas=metadatas,
            persist_directory=str(self.persist_directory),
            collection_name="thesis_subjects"
        )
        
        # self.vectorstore.persist()
        logger.info(f"üîÑ Base recr√©√©e avec {len(texts)} sujets")
                
    def search_similar(self, query: str, k: int = 10, filters: dict = None):
        """
        Recherche am√©lior√©e avec fallback si pas de r√©sultats
        """
        # Essai 1: Avec filtres
        results = self.vectorstore.similarity_search_with_score(
            query=query,
            k=k,
            filter=filters
        )
        
        # Si pas de r√©sultats avec filtres, essayer sans filtres
        if not results and filters:
            logger.info("   Aucun r√©sultat avec filtres, recherche sans filtres...")
            results = self.vectorstore.similarity_search_with_score(
                query=query,
                k=k,
                filter=None
            )
        
        # Si toujours pas de r√©sultats, √©largir la recherche
        if not results:
            logger.info("   Recherche √©largie avec requ√™te plus g√©n√©rale...")
            # Simplifier la requ√™te
            simple_query = " ".join(query.split()[:5])  # Premiers 5 mots
            results = self.vectorstore.similarity_search_with_score(
                query=simple_query,
                k=k,
                filter=None
            )
                
        if not self.vectorstore:
            logger.error("‚ùå Vectorstore non initialis√©")
            return []
        
        try:
            logger.debug(f"üîç Recherche pour: '{query[:50]}...'")
            
            # Recherche par similarit√©
            results = self.vectorstore.similarity_search_with_score(
                query=query,
                k=k,
                filter=filters
            )
            
            # Formatage des r√©sultats
            formatted_results = []
            for doc, score in results:
                result = {
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "score": float(score)
                }
                formatted_results.append(result)
            
            logger.info(f"üìä {len(formatted_results)} r√©sultats trouv√©s")
            return formatted_results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la recherche: {str(e)}")
            return []

    def _understand_intent(self, user_input: str, conversation_history: list) -> dict:
        """
        Comprend l'intention de l'utilisateur
        """
        intent = {
            "type": "new_query",  # Par d√©faut
            "referenced_topic": None,
            "action": "generate"
        }
        
        input_lower = user_input.lower()
        
        # D√©tection des r√©f√©rences
        if any(word in input_lower for word in ["sujet 1", "premier sujet", "le sujet 1"]):
            intent["type"] = "reference"
            intent["referenced_topic"] = 1
            intent["action"] = "elaborate"
        
        elif any(word in input_lower for word in ["d√©velopper", "√©laborer", "exploiter", "approfondir"]):
            intent["type"] = "elaboration"
            intent["action"] = "elaborate"
        
        elif any(word in input_lower for word in ["autre", "diff√©rent", "nouveau"]):
            intent["type"] = "variation"
            intent["action"] = "generate_variation"
        
        return intent
    
    def get_vectorstore_info(self) -> dict:
        """Retourne des informations sur le vectorstore"""
        if not self.vectorstore:
            return {"status": "non_initialise"}
        
        try:
            count = self.vectorstore._collection.count()
            return {
                "status": "initialise",
                "documents_count": count,
                "persist_directory": str(self.persist_directory)
            }
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la r√©cup√©ration des infos: {str(e)}")
            return {"status": "erreur", "error": str(e)}